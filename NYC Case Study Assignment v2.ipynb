{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing SparkSession and creating a spark object\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NYC Case Study Assigment Shubham\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Summons Number: bigint, Plate ID: string, Registration State: string, Issue Date: timestamp, Violation Code: int, Vehicle Body Type: string, Vehicle Make: string, Violation Precinct: int, Issuer Precinct: int, Violation Time: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading the data into DataFrame\n",
    "df = spark.read.format(\"csv\").load('/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv', header=True,inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summons Number',\n",
       " 'Plate ID',\n",
       " 'Registration State',\n",
       " 'Issue Date',\n",
       " 'Violation Code',\n",
       " 'Vehicle Body Type',\n",
       " 'Vehicle Make',\n",
       " 'Violation Precinct',\n",
       " 'Issuer Precinct',\n",
       " 'Violation Time']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Top 5 rows \n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10803028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the count of records in the dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total no. of tickets for the year are 10,803,028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT Registration State)|\n",
      "+----------------------------------+\n",
      "|                                67|\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting Distinct Registration States \n",
    "from pyspark.sql.functions import col, mean,  countDistinct, count\n",
    "\n",
    "df.select('Registration State').agg(countDistinct('Registration State')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 67 distinct Registration State but it has 99 value it in. Let's take care of that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|Registration State|frequency|\n",
      "+------------------+---------+\n",
      "|                NY|  8481061|\n",
      "|                NJ|   925965|\n",
      "|                PA|   285419|\n",
      "|                FL|   144556|\n",
      "|                CT|   141088|\n",
      "|                MA|    85547|\n",
      "|                IN|    80749|\n",
      "|                VA|    72626|\n",
      "|                MD|    61800|\n",
      "|                NC|    55806|\n",
      "|                IL|    37329|\n",
      "|                GA|    36852|\n",
      "|                99|    36625|\n",
      "|                TX|    36516|\n",
      "|                AZ|    26426|\n",
      "|                OH|    25302|\n",
      "|                CA|    24260|\n",
      "|                SC|    21836|\n",
      "|                ME|    21574|\n",
      "|                MN|    18227|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking Frequency of tickets in each Registration State\n",
    "df.groupBy('Registration State').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since, NY has the maximum number of tickets replacing 99 with NY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 99 with the NY as it has most number of tickets issued in the given year \n",
    "from pyspark.sql.functions import * \n",
    "df = df.withColumn('Registration State', regexp_replace('Registration State', '99', 'NY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|Registration State|frequency|\n",
      "+------------------+---------+\n",
      "|                NY|  8517686|\n",
      "|                NJ|   925965|\n",
      "|                PA|   285419|\n",
      "|                FL|   144556|\n",
      "|                CT|   141088|\n",
      "|                MA|    85547|\n",
      "|                IN|    80749|\n",
      "|                VA|    72626|\n",
      "|                MD|    61800|\n",
      "|                NC|    55806|\n",
      "|                IL|    37329|\n",
      "|                GA|    36852|\n",
      "|                TX|    36516|\n",
      "|                AZ|    26426|\n",
      "|                OH|    25302|\n",
      "|                CA|    24260|\n",
      "|                SC|    21836|\n",
      "|                ME|    21574|\n",
      "|                MN|    18227|\n",
      "|                OK|    18165|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Registration State').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT Registration State)|\n",
      "+----------------------------------+\n",
      "|                                66|\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting Distinct Registration States Post fixing 99 column value\n",
    "df.select('Registration State').agg(countDistinct('Registration State')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have 66 distinct Registration States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. How often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|Violation Code|frequency|\n",
      "+--------------+---------+\n",
      "|            21|  1528588|\n",
      "|            36|  1400614|\n",
      "|            38|  1062304|\n",
      "|            14|   893498|\n",
      "|            20|   618593|\n",
      "+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Violation Code').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most violated code is '21' about 1.53 Million times followed by '36' about 1.40 Million times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|Vehicle Body Type|frequency|\n",
      "+-----------------+---------+\n",
      "|             SUBN|  3719802|\n",
      "|             4DSD|  3082020|\n",
      "|              VAN|  1411970|\n",
      "|             DELV|   687330|\n",
      "|              SDN|   438191|\n",
      "+-----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by Vehicle Body type and printing top 5 rows \n",
    "df.groupBy('Vehicle Body Type').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|Vehicle Make|frequency|\n",
      "+------------+---------+\n",
      "|        FORD|  1280958|\n",
      "|       TOYOT|  1211451|\n",
      "|       HONDA|  1079238|\n",
      "|       NISSA|   918590|\n",
      "|       CHEVR|   714655|\n",
      "+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by Vehicle maker and printing top 5 rows\n",
    "df.groupBy('Vehicle Make').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBN vehicle body type got most number of tickets about 3.72 Mn followed by 4DSD 3.08 Mn\n",
    "#### FORD vehicles have the highest frequency of tickets about 1.28 Mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 'Violation Precinct' tickets frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|Violation Precinct|frequency|\n",
      "+------------------+---------+\n",
      "|                 0|  2072400|\n",
      "|                19|   535671|\n",
      "|                14|   352450|\n",
      "|                 1|   331810|\n",
      "|                18|   306920|\n",
      "|               114|   296514|\n",
      "+------------------+---------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking Violation Precinct wise Tickets frequency\n",
    "df.groupBy('Violation Precinct').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring '0' as these are erroreous entries. The most tickets are from 19 (5.35 Mn) followed by 14 (3.52 Mn) Precinct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 'Issuer Precinct' tickets frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|Issuer Precinct|frequency|\n",
      "+---------------+---------+\n",
      "|              0|  2388479|\n",
      "|             19|   521513|\n",
      "|             14|   344977|\n",
      "|              1|   321170|\n",
      "|             18|   296553|\n",
      "|            114|   289950|\n",
      "+---------------+---------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking Issuer Precint wise Tickets frequency \n",
    "df.groupBy('Issuer Precinct').agg(count('Summons Number').alias('frequency')).sort(col('frequency').desc()).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring '0' as these are erroreous entries. The most tickets are issued by 19 (5.21 Mn) followed by 14 (3.45 Mn) Precinct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Find the violation code frequencies for three precincts that have issued the most number of tickets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|Violation Code|frequency|\n",
      "+--------------+---------+\n",
      "|            14|   210865|\n",
      "|            46|   129758|\n",
      "|            38|    97816|\n",
      "|            37|    89584|\n",
      "|            69|    73875|\n",
      "|            16|    72237|\n",
      "|            21|    68782|\n",
      "|            20|    61902|\n",
      "|            31|    54868|\n",
      "|            19|    36819|\n",
      "|            40|    36506|\n",
      "|            47|    32672|\n",
      "|            71|    28177|\n",
      "|            42|    27740|\n",
      "|            84|    25420|\n",
      "|            17|    23484|\n",
      "|            10|    20706|\n",
      "|            70|    15199|\n",
      "|            82|    12569|\n",
      "|             9|    11122|\n",
      "+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# register DataFrame as temp table\n",
    "df.createOrReplaceTempView(\"nyc_table\")\n",
    "# after registering temp table you we run your sql queries\n",
    "spark.sql('''\n",
    "\n",
    "select `Violation Code`, count(*) as frequency\n",
    "from nyc_table\n",
    "where `Violation Precinct` in ('19', '14', '1')\n",
    "group by `Violation Code`\n",
    "order by frequency desc\n",
    "\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violation Code# 14 (~211K) is the most frequent reason for a ticket followed by 46 (~130K) & 38 (~98K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+----+\n",
      "| vp| vc|frequency|rank|\n",
      "+---+---+---------+----+\n",
      "|  1| 14|    76375|   1|\n",
      "|  1| 16|    39197|   2|\n",
      "|  1| 20|    28768|   3|\n",
      "| 19| 46|    90530|   1|\n",
      "| 19| 38|    74926|   2|\n",
      "| 19| 37|    73359|   3|\n",
      "| 14| 14|    75850|   1|\n",
      "| 14| 69|    58032|   2|\n",
      "| 14| 31|    40150|   3|\n",
      "+---+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to get Violation code for Top Violation Precinct i.e 19, 14 & 1\n",
    "spark.sql('''\n",
    "select * \n",
    "from \n",
    "(select *, dense_rank() over (partition by vp order by frequency desc ) as rank\n",
    "from \n",
    "(select `Violation Precinct` as vp, `Violation Code` as vc, count(*) as frequency\n",
    "from nyc_table\n",
    "where `Violation Precinct` in ('19', '14', '1')\n",
    "group by `Violation Precinct`, `Violation Code`\n",
    "order by frequency desc\n",
    ")a\n",
    ")b \n",
    "where rank <= 3 \n",
    "\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Pricent 19, Most violated code is 46 (90.5K) followed by 38 (74.9K) \n",
    "#### In Pricent 1, Most violated code is 14 (76.3K) followed by 16 (~39K) \n",
    "#### In Pricent 14, Most violated code is 14 (75.8K) followed by 69 (~58K) \n",
    "\n",
    "#### Violation Code 14 is highest in Pricent 1 & 14 leading to becoming the most frequent reason for a violation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Find out the properties of parking violations across different times of the day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for null values and handling them by dropping it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking null values \n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10803028"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping any null value, if any\n",
    "df =  df.dropna(how='any')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like we don't have any null value. Let's continue with correcting Violation time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|                 ts|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|        0143AM|1970-01-01 01:43:00|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|        0400PM|1970-01-01 16:00:00|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|        0233PM|1970-01-01 14:33:00|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|        1120AM|1970-01-01 11:20:00|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|        0555PM|1970-01-01 17:55:00|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting Violation Time into suitable format \n",
    "import pyspark.sql.functions as F \n",
    "df2 = df.withColumn('Violation Time', F.concat(F.col('Violation Time'), F.lit('M')))\n",
    "df3 = df2.withColumn('ts', F.to_timestamp('Violation Time','hhmma'))\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+-----+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|                 ts| time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+-----+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|        0143AM|1970-01-01 01:43:00|01:43|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|        0400PM|1970-01-01 16:00:00|16:00|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|        0233PM|1970-01-01 14:33:00|14:33|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|        1120AM|1970-01-01 11:20:00|11:20|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|        0555PM|1970-01-01 17:55:00|17:55|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspecting top 5 rows post time format treatment\n",
    "df4 = df3.withColumn('time', F.date_format(F.col('ts'), format='HH:mm'))\n",
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 Time Bucket wise Most Violated Code Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---------+----+\n",
      "|time_bucket| vc|frequency|rank|\n",
      "+-----------+---+---------+----+\n",
      "|   16-20 Hr| 38|   203232|   1|\n",
      "|   16-20 Hr| 37|   145784|   2|\n",
      "|   16-20 Hr| 14|   144748|   3|\n",
      "|     0-4 Hr| 21|    53600|   1|\n",
      "|     0-4 Hr| 40|    44737|   2|\n",
      "|     0-4 Hr| 78|    28716|   3|\n",
      "|     Others| 21|    23925|   1|\n",
      "|     Others| 14|     8029|   2|\n",
      "|     Others| 40|     6263|   3|\n",
      "|     4-8 Hr| 14|   141275|   1|\n",
      "|     4-8 Hr| 21|   119466|   2|\n",
      "|     4-8 Hr| 40|   112186|   3|\n",
      "|   20-24 Hr|  7|    65593|   1|\n",
      "|   20-24 Hr| 38|    47029|   2|\n",
      "|   20-24 Hr| 14|    44778|   3|\n",
      "|   12-16 Hr| 36|   588395|   1|\n",
      "|   12-16 Hr| 38|   462756|   2|\n",
      "|   12-16 Hr| 37|   337074|   3|\n",
      "|    8-12 Hr| 21|  1182676|   1|\n",
      "|    8-12 Hr| 36|   751422|   2|\n",
      "|    8-12 Hr| 38|   346518|   3|\n",
      "+-----------+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# register df4 as temp table\n",
    "df4.createOrReplaceTempView(\"nyc_table\")\n",
    "\n",
    "# Getting top three Violation codes in each time bucket \n",
    "spark.sql('''\n",
    "select * \n",
    "from \n",
    "(select *, dense_rank() over (partition by time_bucket order by frequency desc) as rank \n",
    "from \n",
    "(\n",
    "select (case \n",
    "when time < '04:00' then '0-4 Hr' \n",
    "when time < '08:00' then '4-8 Hr'\n",
    "when time < '12:00' then '8-12 Hr'\n",
    "when time < '16:00' then '12-16 Hr'\n",
    "when time < '20:00' then '16-20 Hr'\n",
    "when time <= '24:00' then '20-24 Hr'\n",
    "else 'Others'\n",
    "end) as time_bucket, `Violation Code` as vc, count(*) as frequency\n",
    "from nyc_table\n",
    "group by time_bucket, `Violation Code`\n",
    "order by frequency desc\n",
    ")a\n",
    ")b \n",
    "where rank <= 3 \n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that in different time bucket we have different violation code. During late night hours i.e 0-4 Hr & 4-8 Hr bucket we can see 21 & 14 respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.2 Time Bucket wise Tickets Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|time_bucket|frequency|\n",
      "+-----------+---------+\n",
      "|    8-12 Hr|  4306112|\n",
      "|   12-16 Hr|  3591491|\n",
      "|   16-20 Hr|  1296358|\n",
      "|     4-8 Hr|   883502|\n",
      "|   20-24 Hr|   382297|\n",
      "|     0-4 Hr|   284430|\n",
      "|     Others|    58838|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query for getting Time Bucket wise Tickets frequency \n",
    "spark.sql('''\n",
    "select (case \n",
    "when time < '04:00' then '0-4 Hr' \n",
    "when time < '08:00' then '4-8 Hr'\n",
    "when time < '12:00' then '8-12 Hr'\n",
    "when time < '16:00' then '12-16 Hr'\n",
    "when time < '20:00' then '16-20 Hr'\n",
    "when time <= '24:00' then '20-24 Hr'\n",
    "else 'Others'\n",
    "end) as time_bucket,  count(*) as frequency\n",
    "from nyc_table\n",
    "group by time_bucket\n",
    "order by frequency desc\n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most of the tickets are issued using Morning & Afternoon hours i.e 8-12 Hr & 12-16 Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|time_bucket|frequency|\n",
      "+-----------+---------+\n",
      "|    8-12 Hr|  1803478|\n",
      "|   12-16 Hr|   867065|\n",
      "|   16-20 Hr|   348531|\n",
      "|     4-8 Hr|   263041|\n",
      "|   20-24 Hr|    92170|\n",
      "|     0-4 Hr|    78134|\n",
      "|     Others|    31971|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query for getting Time Bucket wise Tickets frequency for most common Violation Code i.e 21, 14 & 38\n",
    "spark.sql('''\n",
    "select (case \n",
    "when time < '04:00' then '0-4 Hr' \n",
    "when time < '08:00' then '4-8 Hr'\n",
    "when time < '12:00' then '8-12 Hr'\n",
    "when time < '16:00' then '12-16 Hr'\n",
    "when time < '20:00' then '16-20 Hr'\n",
    "when time <= '24:00' then '20-24 Hr'\n",
    "else 'Others'\n",
    "end) as time_bucket,  count(*) as frequency\n",
    "from nyc_table\n",
    "where `Violation Code` in ('14','21', '38')\n",
    "group by time_bucket\n",
    "order by frequency desc\n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For most common Violation Code which is 14, 21 & 38. Most Tickets were issued in the morning 8-12 Hr (~1.80 Mn) followed by Aternoon 12-16 Hr (~867K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Checking Seasonality in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|month|frequency|\n",
      "+-----+---------+\n",
      "|    6|  1103400|\n",
      "|    5|  1026534|\n",
      "|   10|   969825|\n",
      "|    3|   965247|\n",
      "|    9|   961128|\n",
      "|   11|   899849|\n",
      "|    4|   888906|\n",
      "|    1|   878580|\n",
      "|    2|   827505|\n",
      "|    8|   801774|\n",
      "|   12|   779246|\n",
      "|    7|   701034|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to get month wise tickets frequency \n",
    "spark.sql('''\n",
    "\n",
    "select extract(month from `Issue Date`) as month,  count(*) as frequency\n",
    "from nyc_table\n",
    "group by month\n",
    "order by frequency desc\n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, June is the month in which most of the tickets were issued i.e ~1.10 Mn followed by May (~1.03 Mn) and then October ~9.70 Mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|seasons|frequency|\n",
      "+-------+---------+\n",
      "| Spring|  2880687|\n",
      "| Autumn|  2830802|\n",
      "| Summer|  2606208|\n",
      "| Winter|  2485331|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query for season wise Tickets frequency \n",
    "spark.sql('''\n",
    "\n",
    "select (case \n",
    "when month in (3,4,5) then 'Spring' \n",
    "when month in (6,7,8) then 'Summer'\n",
    "when month in (9,10,11) then 'Autumn'\n",
    "when month in (12,1,2) then 'Winter' \n",
    "else null end ) as seasons, sum(frequency) as frequency  \n",
    "from \n",
    "(select extract(month from `Issue Date`) as month,  count(*) as frequency\n",
    "from nyc_table\n",
    "group by month\n",
    "order by frequency desc\n",
    ")a\n",
    "group by seasons\n",
    "order by frequency desc \n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The highest number of tickets are issued in Spring season but there is not much of a significant difference in frequency across seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+----+\n",
      "|seasons| vc|frequency|rank|\n",
      "+-------+---+---------+----+\n",
      "| Spring| 21|   402807|   1|\n",
      "| Spring| 36|   344834|   2|\n",
      "| Spring| 38|   271192|   3|\n",
      "| Summer| 21|   405961|   1|\n",
      "| Summer| 38|   247561|   2|\n",
      "| Summer| 36|   240396|   3|\n",
      "| Autumn| 36|   456046|   1|\n",
      "| Autumn| 21|   357479|   2|\n",
      "| Autumn| 38|   283828|   3|\n",
      "| Winter| 21|   362341|   1|\n",
      "| Winter| 36|   359338|   2|\n",
      "| Winter| 38|   259723|   3|\n",
      "+-------+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query for getting top Violation codes for each season based on tickets issued \n",
    "spark.sql('''\n",
    "select * \n",
    "from \n",
    "(\n",
    "select *, dense_rank() over (partition by seasons order by frequency desc) as rank \n",
    "from \n",
    "(\n",
    "select (case \n",
    "when month in (3,4,5) then 'Spring' \n",
    "when month in (6,7,8) then 'Summer'\n",
    "when month in (9,10,11) then 'Autumn'\n",
    "when month in (12,1,2) then 'Winter' \n",
    "else null end ) as seasons, vc, sum(frequency) as frequency  \n",
    "from \n",
    "(\n",
    "select extract(month from `Issue Date`) as month, `Violation Code` as vc, count(*) as frequency\n",
    "from nyc_table\n",
    "group by month, vc\n",
    "order by frequency desc\n",
    ")c\n",
    "group by seasons, vc\n",
    "order by frequency desc \n",
    ")a\n",
    ")b \n",
    "where rank <= 3 \n",
    "\n",
    "\n",
    "''').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Spring Season Top 3 Violation Codes are 21, 23 & 38 \n",
    "#### In Summer Season Top 3 Violation Codes are 21, 38 & 36\n",
    "#### In Autumn Season Top 3 Violation Codes are 36, 21 & 38 \n",
    "#### In Winter Season Top 3 Violation Codes are 21, 36 & 38 \n",
    "\n",
    "#### 21 & 38 Violation Code has occured among Top 3 Violation Code across seasons \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Revenue Collection from Tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|Violation Code|frequency|\n",
      "+--------------+---------+\n",
      "|            21|  1528588|\n",
      "|            36|  1400614|\n",
      "|            38|  1062304|\n",
      "|            14|   893498|\n",
      "|            20|   618593|\n",
      "+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query for Violation Code tickets frequency \n",
    "spark.sql('''\n",
    "select `Violation Code`,  count(*) as frequency\n",
    "from nyc_table\n",
    "group by `Violation Code`\n",
    "order by frequency desc \n",
    "\n",
    "''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 3 Violation Codes are 21, 36 & 38 with  1,528,588, 1,400,614 & 1,062,304 respectively\n",
    "#### Violation Code 21 (No Parking) Fine is USD 55\n",
    "#### Violation Code 36 (Exceeding the posted speed limit in or near a designated school zone) Fine is USD 50\n",
    "#### Violation Code 38 (Failing to show a receipt or tag in the windshield) is USD 50\n",
    "\n",
    "#### Total Revenue collection from Top 3 Tickets is USD (55x1,528,588, + 50x1,400,614  + 50x1,062,304)  = USD 207,218,240\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "#### 1. Most of the Tickets were due No Parking, Over speeding or Exceeding Parking Time Limit / showing relevant documents for the same\n",
    "#### 2. There no much of a significant impact of season on tickets count \n",
    "#### 3. Most of the tickets were issued during the morning peak hours 8-12 Hr followed by afternoon hours of 12-4 Hrs\n",
    "#### 4. Most Tickets were issued in 19, 1 & 14 Precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
